{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ce3547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the needed packages/lib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d709d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call this func selectkbest and input x and y variable along with declaring no of variables\n",
    "def selectkbest(indep_X,dep_Y,n):\n",
    "        #calling selectKbest algo + eval metrics = Chi square + decalring no of features\n",
    "        test = SelectKBest(score_func=chi2, k=n)\n",
    "        #fit the model selectKbest & input indep, dep variable\n",
    "        fit1= test.fit(indep_X,dep_Y)\n",
    "        #Transform selectKbest algo + eval metrics = Chi square + declared no of features into indep_x variable      \n",
    "        selectk_features = fit1.transform(indep_X)\n",
    "        return selectk_features # finally return to selectk_features variable\n",
    "    \n",
    "def split_scalar(indep_X,dep_Y): # call this func split_scalar and input x and y\n",
    "        # Training & test split happening here\n",
    "        X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size = 0.25, random_state = 0)\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)# Fit & transform standardscalar ex from -1 to +1 or -2 or +2 to x_train\n",
    "        X_test = sc.transform(X_test)#Alreday fitted so tranaform standardscalar ex from -1 to +1 or -2 or +2 to x_test   \n",
    "        return X_train, X_test, y_train, y_test # finally return to X_train, X_test, y_train, y_test.\n",
    "    \n",
    "# regressor variable holds model below(Linear,svm_linear,svm_NL,DT,RF),x_test to predict y(predicted), y_test(Actual) \n",
    "# to be used to compare with y_pred to arrive R2_score value. \n",
    "def r2_prediction(regressor,X_test,y_test):\n",
    "     y_pred = regressor.predict(X_test)\n",
    "     from sklearn.metrics import r2_score # Making the r2_score\n",
    "     r2=r2_score(y_test,y_pred) # creating r2_score to comparing Acutal vs predicted\n",
    "     return r2 # finally return to r2 variable\n",
    "  \n",
    "def Linear(X_train,y_train,X_test):#Passing X_train,y_train to fit to the model and x_test to predict Y in cm_prediction      \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        regressor = LinearRegression()\n",
    "        regressor.fit(X_train, y_train)\n",
    "        # can predict R2 scoring & assigning to R2 variable\n",
    "        r2=r2_prediction(regressor,X_test,y_test)\n",
    "        return  r2 # finally return to R2\n",
    "    \n",
    "         # SAME APPLICABLE TO ALL OTHER ALGO BELOW\n",
    "    \n",
    "def svm_linear(X_train,y_train,X_test):\n",
    "                \n",
    "        from sklearn.svm import SVR\n",
    "        regressor = SVR(kernel = 'linear')\n",
    "        regressor.fit(X_train, y_train)\n",
    "        r2=r2_prediction(regressor,X_test,y_test)\n",
    "        return  r2  \n",
    "    \n",
    "def svm_NL(X_train,y_train,X_test):\n",
    "                \n",
    "        from sklearn.svm import SVR\n",
    "        regressor = SVR(kernel = 'rbf')\n",
    "        regressor.fit(X_train, y_train)\n",
    "        r2=r2_prediction(regressor,X_test,y_test)\n",
    "        return  r2  \n",
    "     \n",
    "\n",
    "def Decision(X_train,y_train,X_test):\n",
    "        \n",
    "        # Fitting K-NN to the Training setC\n",
    "        from sklearn.tree import DecisionTreeRegressor\n",
    "        regressor = DecisionTreeRegressor(random_state = 0)\n",
    "        regressor.fit(X_train, y_train)\n",
    "        r2=r2_prediction(regressor,X_test,y_test)\n",
    "        return  r2  \n",
    "     \n",
    "\n",
    "def random(X_train,y_train,X_test):       \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "        regressor.fit(X_train, y_train)\n",
    "        r2=r2_prediction(regressor,X_test,y_test)\n",
    "        return  r2 \n",
    "    \n",
    "    \n",
    "def selectk_regression(acclin,accsvml,accsvmnl,accdes,accrf): \n",
    "    # Create a Dataframe (table) with row ChiSquare and cols specified in cols\n",
    "    dataframe=pd.DataFrame(index=['ChiSquare'],columns=['Linear','SVMl','SVMnl','Decision','Random'])\n",
    "    # Using For loop index placing the scoring from 0 to 5 to its respective algo                            \n",
    "    for number,index in enumerate(dataframe.index):\n",
    "        \n",
    "        dataframe['Linear'][index]=acclin[number]       \n",
    "        dataframe['SVMl'][index]=accsvml[number]\n",
    "        dataframe['SVMnl'][index]=accsvmnl[number]\n",
    "        dataframe['Decision'][index]=accdes[number]\n",
    "        dataframe['Random'][index]=accrf[number]\n",
    "    return dataframe # return the function to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0c7cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1=pd.read_csv(\"prep.csv\",index_col=None)# reading.loading the csv dataset \n",
    "\n",
    "df2=dataset1 # taking a back up of original dataset\n",
    "\n",
    "df2 = pd.get_dummies(df2, drop_first=True) # remove first redundant col wrt to nominal col\n",
    "\n",
    "indep_X=df2.drop('classification_yes', axis=1)# dropping 'classification_yes' from indep_x variable\n",
    "dep_Y=df2['classification_yes'] # calling dep_y 'classification_yes'\n",
    "\n",
    "# calling SelectKBest func inputting indep_X,dep_Y and no of feature in args from sklearn.feature_selection import SelectKBest    \n",
    "kbest=selectkbest(indep_X,dep_Y,6)      \n",
    "# created a empty list to append the final value\n",
    "acclin=[]\n",
    "accsvml=[]\n",
    "accsvmnl=[]\n",
    "accdes=[]\n",
    "accrf=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0571770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.00000000e+00, 1.48112676e+02, 5.74821053e+01, 3.07735602e+00,\n",
       "        3.88689024e+01, 8.40819113e+03],\n",
       "       [2.00000000e+00, 1.48112676e+02, 2.20000000e+01, 7.00000000e-01,\n",
       "        3.40000000e+01, 1.23000000e+04],\n",
       "       [1.00000000e+00, 9.90000000e+01, 2.30000000e+01, 6.00000000e-01,\n",
       "        3.40000000e+01, 8.40819113e+03],\n",
       "       ...,\n",
       "       [3.00000000e+00, 1.10000000e+02, 1.15000000e+02, 6.00000000e+00,\n",
       "        2.60000000e+01, 9.20000000e+03],\n",
       "       [0.00000000e+00, 2.07000000e+02, 8.00000000e+01, 6.80000000e+00,\n",
       "        3.88689024e+01, 8.40819113e+03],\n",
       "       [0.00000000e+00, 1.00000000e+02, 4.90000000e+01, 1.00000000e+00,\n",
       "        5.30000000e+01, 8.50000000e+03]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3965a9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the 6 feature we are spliting X_train, X_test, y_train, y_test & calling split_scalar and i/p 6 feature and dep_y\n",
    "X_train, X_test, y_train, y_test=split_scalar(kbest,dep_Y)  \n",
    "\n",
    "#creating a for loop to iterate each 6 feature of indep_x and dep_y\n",
    "for i in kbest: \n",
    "    #calling linear func and passing X_train,y_train,X_test to predict and append R2_score value in the empty list\n",
    "    r2_lin=Linear(X_train,y_train,X_test)\n",
    "    acclin.append(r2_lin)\n",
    "   \n",
    "    \n",
    "    r2_sl=svm_linear(X_train,y_train,X_test)    \n",
    "    accsvml.append(r2_sl)\n",
    "    \n",
    "    r2_NL=svm_NL(X_train,y_train,X_test)\n",
    "    accsvmnl.append(r2_NL)\n",
    "    \n",
    "    r2_d=Decision(X_train,y_train,X_test)\n",
    "    accdes.append(r2_d)\n",
    "    \n",
    "    r2_r=random(X_train,y_train,X_test)\n",
    "    accrf.append(r2_r)\n",
    "    \n",
    "# finally calling selectk_regression func and input neccessary args \n",
    "result= selectk_regression(acclin,accsvml,accsvmnl,accdes,accrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b7261a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear</th>\n",
       "      <th>SVMl</th>\n",
       "      <th>SVMnl</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ChiSquare</th>\n",
       "      <td>0.599041</td>\n",
       "      <td>0.586446</td>\n",
       "      <td>0.838962</td>\n",
       "      <td>0.869792</td>\n",
       "      <td>0.897569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Linear      SVMl     SVMnl  Decision    Random\n",
       "ChiSquare  0.599041  0.586446  0.838962  0.869792  0.897569"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finally print the value in the table\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
